{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c251b6b5-7a7c-44b2-ac87-279ab80f5b1a",
      "metadata": {
        "id": "c251b6b5-7a7c-44b2-ac87-279ab80f5b1a",
        "outputId": "aaa5d359-d90e-492f-e7c5-3972e741186f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import MyModel\n",
        "from data import get_valid_transforms, MyDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")\n",
        "\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1227e217-f3a3-4d44-898c-baf5d90b3dc7",
      "metadata": {
        "id": "1227e217-f3a3-4d44-898c-baf5d90b3dc7"
      },
      "outputs": [],
      "source": [
        "class MyModel_drop(nn.Module): # model from team member\n",
        "    def __init__(self, n_classes, model_name):\n",
        "        super(MyModel_drop, self).__init__()\n",
        "        self.feature = timm.create_model(model_name, pretrained=False)\n",
        "\n",
        "        self.out_features = self.feature.fc.in_features\n",
        "        self.feature.fc = nn.Linear(in_features=self.out_features, out_features=self.out_features//4, bias=True) \n",
        "        self.out = nn.Linear(in_features=self.out_features//4, out_features=n_classes, bias=True)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.out(x)\n",
        "        return x    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42148c0-12c7-40a2-b108-24cb1e0fb5ab",
      "metadata": {
        "id": "c42148c0-12c7-40a2-b108-24cb1e0fb5ab"
      },
      "outputs": [],
      "source": [
        "densenet_paths = [i for i in glob('./saved/densenetblur121d/*')]\n",
        "resnet50_paths = [i for i in glob('./saved/gluon_seresnext50_32x4d/*')]\n",
        "inception_paths = [i for i in glob('./saved/inception_v3/*')]\n",
        "resnet26_paths = [i for i in glob('./saved/seresnext26d_32x4d/*')]\n",
        "ensemble_paths = resnet50_paths + densenet_paths + resnet26_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aab2cc4-0e06-422d-b950-a73bf33689d0",
      "metadata": {
        "id": "7aab2cc4-0e06-422d-b950-a73bf33689d0",
        "outputId": "eb5cf77b-dd95-449b-8863-f5046fc88dbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['./saved/gluon_seresnext50_32x4d/seresnext50_seed7_1_best_acc_113_0.9231.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_2_best_acc_129_0.9077.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_seed7_2_best_acc_108_0.9308.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_4_best_acc_96_0.9538.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_1_best_acc_102_0.9462.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_seed7_4_best_acc_119_0.9231.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_3_best_acc_82_0.9308.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_0_best_acc_91_0.9538.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_seed7_0_best_acc_113_0.9308.pt',\n",
              " './saved/gluon_seresnext50_32x4d/seresnext50_seed7_3_best_acc_127_0.9308.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_seed7_3_best_acc_74_0.9538.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_4_best_acc_88_0.9615.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_1_best_acc_82_0.9231.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_seed7_0_best_acc_57_0.9385.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_3_best_acc_76_0.9462.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_seed7_4_best_acc_72_0.9538.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_seed7_1_best_acc_75_0.9154.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_seed7_2_best_acc_47_0.9538.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_0_best_acc_70_0.9538.pt',\n",
              " './saved/densenetblur121d/densenetblur121d_2_best_acc_96_0.9077.pt',\n",
              " './saved/seresnext26d_32x4d/4_0.9846_seresnext26d_32x4d_2Aug.pth',\n",
              " './saved/seresnext26d_32x4d/0_0.9692_seresnext26d_32x4d_2Aug.pth',\n",
              " './saved/seresnext26d_32x4d/3_0.9538_seresnext26d_32x4d_2Aug.pth',\n",
              " './saved/seresnext26d_32x4d/1_0.9385_seresnext26d_32x4d_2Aug.pth',\n",
              " './saved/seresnext26d_32x4d/2_0.9154_seresnext26d_32x4d_2Aug.pth']"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad197b37-16fd-4154-b1e9-babb8c065f8f",
      "metadata": {
        "id": "ad197b37-16fd-4154-b1e9-babb8c065f8f"
      },
      "outputs": [],
      "source": [
        "# model names\n",
        "densenet = 'densenetblur121d'\n",
        "resnet50 = 'gluon_seresnext50_32x4d'\n",
        "inception = 'gluon_inception_v3'\n",
        "resnet26 = 'seresnext26d_32x4d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a58f2289-bd95-42af-bd28-c7d109d4fce1",
      "metadata": {
        "id": "a58f2289-bd95-42af-bd28-c7d109d4fce1"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('./data/sample_submission.csv')\n",
        "submission = df_test.copy()\n",
        "test_transforms = get_valid_transforms()\n",
        "test_dataset = MyDataset(df_test.values, test_transforms, color=None, root='./data/test')\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, \n",
        "    batch_size=1,\n",
        "    num_workers=0,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4947b333-7e06-46be-a6c3-a40fe3aee79d",
      "metadata": {
        "id": "4947b333-7e06-46be-a6c3-a40fe3aee79d"
      },
      "outputs": [],
      "source": [
        "def get_stack_logits(model_paths, test_loader, df_test):\n",
        "    stack_logits = torch.zeros(len(df_test), 2).cpu()\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(model_paths):\n",
        "            print(i)\n",
        "            \n",
        "            if 'densenetblur' in i: model = MyModel(2, densenet).to(device)\n",
        "            elif 'resnext50' in i: model = MyModel(2, resnet50).to(device)\n",
        "            elif 'inception' in i: model = MyModel(2, inception).to(device)\n",
        "            elif 'resnext26d' in i: model = MyModel_drop(2, resnet26).to(device)\n",
        "            \n",
        "            temp = []\n",
        "            checkpoint = torch.load(i)\n",
        "            model.load_state_dict(checkpoint['model'])\n",
        "            model.eval()\n",
        "            \n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device).float(), y.to(device).long()\n",
        "                outs = model(x)\n",
        "                outs = outs.detach().cpu()\n",
        "                temp.append(outs)\n",
        "            res = torch.stack(temp, dim=0).squeeze()\n",
        "            print(res.shape)\n",
        "            stack_logits += res\n",
        "    return stack_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8deadd95-228b-4188-ada9-42d5b6f7e408",
      "metadata": {
        "id": "8deadd95-228b-4188-ada9-42d5b6f7e408",
        "outputId": "df8227cc-bc47-47bd-81f3-fe1fda9f29fb",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0% 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./saved/gluon_seresnext50_32x4d/seresnext50_seed7_1_best_acc_113_0.9231.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4% 1/25 [00:08<03:15,  8.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_2_best_acc_129_0.9077.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8% 2/25 [00:16<03:06,  8.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_seed7_2_best_acc_108_0.9308.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12% 3/25 [00:24<02:59,  8.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_4_best_acc_96_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16% 4/25 [00:32<02:51,  8.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_1_best_acc_102_0.9462.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20% 5/25 [00:40<02:41,  8.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_seed7_4_best_acc_119_0.9231.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24% 6/25 [00:48<02:33,  8.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_3_best_acc_82_0.9308.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28% 7/25 [00:57<02:27,  8.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_0_best_acc_91_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32% 8/25 [01:05<02:18,  8.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_seed7_0_best_acc_113_0.9308.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36% 9/25 [01:13<02:09,  8.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/gluon_seresnext50_32x4d/seresnext50_seed7_3_best_acc_127_0.9308.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40% 10/25 [01:21<02:02,  8.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_seed7_3_best_acc_74_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44% 11/25 [01:29<01:52,  8.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_4_best_acc_88_0.9615.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48% 12/25 [01:37<01:43,  7.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_1_best_acc_82_0.9231.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52% 13/25 [01:45<01:35,  7.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_seed7_0_best_acc_57_0.9385.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56% 14/25 [01:52<01:27,  7.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_3_best_acc_76_0.9462.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60% 15/25 [02:01<01:21,  8.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_seed7_4_best_acc_72_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64% 16/25 [02:09<01:13,  8.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_seed7_1_best_acc_75_0.9154.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68% 17/25 [02:18<01:05,  8.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_seed7_2_best_acc_47_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72% 18/25 [02:26<00:57,  8.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_0_best_acc_70_0.9538.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76% 19/25 [02:34<00:48,  8.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/densenetblur121d/densenetblur121d_2_best_acc_96_0.9077.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80% 20/25 [02:42<00:41,  8.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/seresnext26d_32x4d/4_0.9846_seresnext26d_32x4d_2Aug.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84% 21/25 [02:50<00:32,  8.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/seresnext26d_32x4d/0_0.9692_seresnext26d_32x4d_2Aug.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88% 22/25 [02:58<00:24,  8.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/seresnext26d_32x4d/3_0.9538_seresnext26d_32x4d_2Aug.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92% 23/25 [03:06<00:15,  7.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/seresnext26d_32x4d/1_0.9385_seresnext26d_32x4d_2Aug.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96% 24/25 [03:14<00:07,  7.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n",
            "./saved/seresnext26d_32x4d/2_0.9154_seresnext26d_32x4d_2Aug.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% 25/25 [03:22<00:00,  8.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 2])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "stack_logits = get_stack_logits(ensemble_paths, test_loader, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec1fbc6-6163-4a00-9bdb-eaae8849ab03",
      "metadata": {
        "id": "cec1fbc6-6163-4a00-9bdb-eaae8849ab03"
      },
      "outputs": [],
      "source": [
        "def make_submission(logits, submission, file_name):\n",
        "    pred = logits.argmax(-1).cpu().numpy()\n",
        "    submission['COVID'] = pred\n",
        "    submission.to_csv(f'./submissions/_{file_name}.csv', index=False)\n",
        "    check = pd.read_csv(f'./submissions/_{file_name}.csv')\n",
        "    ratio = check['COVID'].sum() / len(check)\n",
        "    return ratio, check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa364f3-7972-4ba2-9c2e-a9a507ac91b8",
      "metadata": {
        "id": "efa364f3-7972-4ba2-9c2e-a9a507ac91b8",
        "outputId": "f6a41358-28dc-4014-9534-1727394fdf85",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.48,\n",
              "    file_name  COVID\n",
              " 0      0.png      0\n",
              " 1      1.png      0\n",
              " 2      2.png      0\n",
              " 3      3.png      1\n",
              " 4      4.png      0\n",
              " 5      5.png      1\n",
              " 6      6.png      1\n",
              " 7      7.png      1\n",
              " 8      8.png      0\n",
              " 9      9.png      1\n",
              " 10    10.png      0\n",
              " 11    11.png      0\n",
              " 12    12.png      0\n",
              " 13    13.png      0\n",
              " 14    14.png      1\n",
              " 15    15.png      0\n",
              " 16    16.png      1\n",
              " 17    17.png      0\n",
              " 18    18.png      0\n",
              " 19    19.png      0\n",
              " 20    20.png      0\n",
              " 21    21.png      0\n",
              " 22    22.png      0\n",
              " 23    23.png      0\n",
              " 24    24.png      1\n",
              " 25    25.png      0\n",
              " 26    26.png      0\n",
              " 27    27.png      0\n",
              " 28    28.png      1\n",
              " 29    29.png      1\n",
              " 30    30.png      1\n",
              " 31    31.png      1\n",
              " 32    32.png      1\n",
              " 33    33.png      0\n",
              " 34    34.png      0\n",
              " 35    35.png      0\n",
              " 36    36.png      0\n",
              " 37    37.png      1\n",
              " 38    38.png      1\n",
              " 39    39.png      0\n",
              " 40    40.png      1\n",
              " 41    41.png      1\n",
              " 42    42.png      0\n",
              " 43    43.png      1\n",
              " 44    44.png      1\n",
              " 45    45.png      1\n",
              " 46    46.png      1\n",
              " 47    47.png      0\n",
              " 48    48.png      1\n",
              " 49    49.png      0\n",
              " 50    50.png      1\n",
              " 51    51.png      1\n",
              " 52    52.png      1\n",
              " 53    53.png      1\n",
              " 54    54.png      0\n",
              " 55    55.png      1\n",
              " 56    56.png      1\n",
              " 57    57.png      1\n",
              " 58    58.png      0\n",
              " 59    59.png      1\n",
              " 60    60.png      1\n",
              " 61    61.png      0\n",
              " 62    62.png      0\n",
              " 63    63.png      0\n",
              " 64    64.png      1\n",
              " 65    65.png      1\n",
              " 66    66.png      1\n",
              " 67    67.png      0\n",
              " 68    68.png      0\n",
              " 69    69.png      0\n",
              " 70    70.png      0\n",
              " 71    71.png      0\n",
              " 72    72.png      0\n",
              " 73    73.png      0\n",
              " 74    74.png      1\n",
              " 75    75.png      0\n",
              " 76    76.png      0\n",
              " 77    77.png      0\n",
              " 78    78.png      1\n",
              " 79    79.png      1\n",
              " 80    80.png      1\n",
              " 81    81.png      1\n",
              " 82    82.png      0\n",
              " 83    83.png      1\n",
              " 84    84.png      1\n",
              " 85    85.png      0\n",
              " 86    86.png      0\n",
              " 87    87.png      1\n",
              " 88    88.png      0\n",
              " 89    89.png      1\n",
              " 90    90.png      0\n",
              " 91    91.png      0\n",
              " 92    92.png      1\n",
              " 93    93.png      1\n",
              " 94    94.png      0\n",
              " 95    95.png      0\n",
              " 96    96.png      1\n",
              " 97    97.png      1\n",
              " 98    98.png      0\n",
              " 99    99.png      1)"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "save_file_name = 'ensemble_submission'\n",
        "make_submission(stack_logits, submission, save_file_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "_inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
