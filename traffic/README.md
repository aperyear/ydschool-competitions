### 제3차 이어드림스쿨 모의경진대회 [AI CONNECT](https://www.aiconnect.kr/main/competition/list)
- 기간: 22. 2월 16일(수) ~ 2월 22일(화) 12:00PM
- 과제: 교통 물류 통행량 시계열 예측 모델
- 목표: 기준시점 이후 7일 간의 도로 통행량을 예측 
- 데이터: 32개 도로의 시간별 통행량 데이터 (21.01~21.05)
- 평가지표: RMSE
- 팀구성: 4명

### 실험 과정
1. 이번 대회도 대회 초반 3일은 각자의 방식대로 EDA와 학습을 진행하며 의견을 나누었다.
2. 주어진 데이터를 분석하면서 이상치와 비어있는 날짜를 확인해 전처리하고,
3. MLP로 모든 도로를 학습하고 한 번에 모든 도로를 예측하는 모델과,
4. LSTM으로 도로마다 학습하고 도로마다 예측하는 모델을 선택했다.
5. RMSE를 낮추는 목표로 scaler, learning rate 등 hyper parameter를 실험했다.

### 실험 성과
- 학습 시 데이터를 1주일 간격으로 몇 주의 데이터를 input으로 줄 것인가가 성능에 큰 차이가 있었다.
- hyper parameter tunning을 통해 최초 학습 때 보다 2배 정도 성능을 향상할 수 있었다..
- MLP와 LSTM의 cv RMSE는 큰 차이가 없었다.
- 하지만, MLP와 LSTM 결과를 앙상블 했을 때 큰 성능 향상이 있었다.
- MLP는 도로 간의 연관성을 학습했고, LSTM은 트랜드를 학습했다고 해석했다.
- 이번 task에서는 cv가 public이나 private 점수에 큰 영향은 주지 않았다.

### 대회 결과
- 15팀 중 2위로 마무리했다.
- RMSE: public 3957 final 4014

### 차별성
- MLP와 LSTM의 두 가지 모델의 결과를 앙상블 했다.

### 개선 가능성
- 데이터 전처리 과정에서 데이터를 더 면밀히 살펴보고 제거하거나 조정할 수 있을 것 같다.
- 이번 task에서는 cv가 public 점수에 큰 영향을 끼치지 않아서, public 점수 맞추기에 급급했던 것 같다.
- 만약 data가 충분히 더 많은 task에서 같은 전략을 취했을 때 cv와 비슷한지 확인이 필요한 것 같다.

### 결론
- 학습 방법이 완전히 다른 두 모델을 앙상블 했을 때 4400 -> 3900으로 유의미한 성능 변화가 있었다.
- 1위 팀은 모델을 사용하지 않았다. 예측해야 하는 주의 전주와 전전주에 다른 비율을 주고 평균을 냈다.
- 대회에서 좋은 성적을 거두기 위해 꼭 모델을 사용하지 않아도 된다는 사례인 것 같다.